{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets for the Content-based Filter\n",
    "\n",
    "This notebook builds the data we will use for creating our content based model. We'll collect the data via a collection of SQL queries from the publicly available Kurier.at dataset in BigQuery.\n",
    "Kurier.at is an Austrian newsite. The goal of these labs is to recommend an article for a visitor to the site. In this lab we collect the data for training, in the subsequent notebook we train the recommender model. \n",
    "\n",
    "This notebook illustrates\n",
    "* how to pull data from BigQuery table and write to local files\n",
    "* how to make reproducible train and test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: tensorflow-hub==0.7.0 in /opt/conda/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub==0.7.0) (3.17.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub==0.7.0) (1.19.5)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub==0.7.0) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: tensorflow==1.15.3 in /opt/conda/lib/python3.7/site-packages (1.15.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (3.17.3)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.13.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.15.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.19.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.16.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (1.41.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.37.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.3) (0.8.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.3) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (58.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (3.3.4)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3) (3.10.0.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Requirement already satisfied: google-cloud-bigquery==1.10 in /opt/conda/lib/python3.7/site-packages (1.10.0)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.10) (2.0.3)\n",
      "Collecting google-cloud-core<0.30dev,>=0.29.0\n",
      "  Using cached google_cloud_core-0.29.1-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.10) (1.31.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (58.2.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (1.35.0)\n",
      "Requirement already satisfied: protobuf<3.18.0,>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (3.17.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (2.25.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (2021.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (1.53.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (1.16.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (21.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media>=0.3.1->google-cloud-bigquery==1.10) (1.1.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (4.7.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media>=0.3.1->google-cloud-bigquery==1.10) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (2021.10.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media>=0.3.1->google-cloud-bigquery==1.10) (2.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery==1.10) (0.4.8)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: google-cloud-core\n",
      "  Attempting uninstall: google-cloud-core\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "    Found existing installation: google-cloud-core 1.7.2\n",
      "    Uninstalling google-cloud-core-1.7.2:\n",
      "      Successfully uninstalled google-cloud-core-1.7.2\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-translate 3.6.0 requires google-cloud-core<3.0.0dev,>=1.3.0, but you have google-cloud-core 0.29.1 which is incompatible.\n",
      "google-cloud-storage 1.42.3 requires google-cloud-core<3.0dev,>=1.6.0; python_version >= \"3.6\", but you have google-cloud-core 0.29.1 which is incompatible.\n",
      "google-cloud-spanner 3.11.1 requires google-cloud-core<3.0dev,>=1.4.1, but you have google-cloud-core 0.29.1 which is incompatible.\n",
      "google-cloud-logging 2.6.0 requires google-cloud-core<3.0.0dev,>=1.4.1, but you have google-cloud-core 0.29.1 which is incompatible.\n",
      "google-cloud-firestore 2.3.4 requires google-cloud-core<3.0.0dev,>=1.4.1, but you have google-cloud-core 0.29.1 which is incompatible.\n",
      "google-cloud-datastore 2.3.0 requires google-cloud-core<3.0.0dev,>=1.4.0, but you have google-cloud-core 0.29.1 which is incompatible.\n",
      "google-cloud-bigtable 2.4.0 requires google-cloud-core<3.0.0dev,>=1.4.1, but you have google-cloud-core 0.29.1 which is incompatible.\n",
      "google-cloud-aiplatform 1.6.0 requires google-cloud-bigquery<3.0.0dev,>=1.15.0, but you have google-cloud-bigquery 1.10.0 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-core-0.29.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-hub==0.7.0\n",
    "!pip3 install --upgrade tensorflow==1.15.3\n",
    "!pip3 install google-cloud-bigquery==1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from google.cloud import bigquery \n",
    "\n",
    "PROJECT = 'qwiklabs-gcp-03-b731988fa21f' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'qwiklabs-gcp-03-b731988fa21f' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-east1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '2.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud  config  set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this helper function to write lists containing article ids, categories, and authors for each article in our database to local file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_disk(my_list, filename):\n",
    "  with open(filename, 'w') as f:\n",
    "    for item in my_list:\n",
    "        line = \"%s\\n\" % item\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull data from BigQuery\n",
    "\n",
    "The cell below creates a local text file containing all the article ids (i.e. 'content ids') in the dataset. \n",
    "\n",
    "Have a look at the original dataset in [BigQuery](https://console.cloud.google.com/bigquery?p=cloud-training-demos&d=GA360_test&t=ga_sessions_sample). Then read through the query below and make sure you understand what it is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample content IDs ['299965853', '299972248', '299410466']\n",
      "The total number of articles is 15634\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "\n",
    "SELECT  \n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY\n",
    "  content_id\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "content_ids_list = bigquery.Client().query(sql).to_dataframe()['content_id'].tolist()\n",
    "write_list_to_disk(content_ids_list, \"content_ids.txt\")\n",
    "print(\"Some sample content IDs {}\".format(content_ids_list[:3]))\n",
    "print(\"The total number of articles is {}\".format(len(content_ids_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 15,634 articles in the database.  \n",
    "Next, we'll create a local file which contains a list of article categories and a list of article authors.\n",
    "\n",
    "Note the change in the index when pulling the article category or author information. Also, we are using the first author of the article to create our author list.  \n",
    "Refer back to the original dataset, use the `hits.customDimensions.index` field to verify the correct index.\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['News', 'Stars & Kultur', 'Lifestyle']\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT  \n",
    "  (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category  \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY   \n",
    "  category\n",
    "\"\"\"\n",
    "categories_list = bigquery.Client().query(sql).to_dataframe()['category'].tolist()\n",
    "write_list_to_disk(categories_list, \"categories.txt\")\n",
    "print(categories_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories are 'News', 'Stars & Kultur', and 'Lifestyle'.  \n",
    "When creating the author list, we'll only use the first author information for each article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sample authors ['Alexander Huber', 'Christine Klafl', 'Philipp Albrechtsberger', 'Wolfgang Atzenhofer', 'Marlene Patsalidis', 'Peter Temel', 'Stefan Hofer', 'Michael Pammesberger', 'Helmut Brandstätter', 'Martina Salomon']\n",
      "The total number of authors is 385\n"
     ]
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  REGEXP_EXTRACT((SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)), r\"^[^,]+\")  AS first_author  \n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY   \n",
    "  first_author\n",
    "\"\"\"\n",
    "authors_list = bigquery.Client().query(sql).to_dataframe()['first_author'].tolist()\n",
    "write_list_to_disk(authors_list, \"authors.txt\")\n",
    "print(\"Some sample authors {}\".format(authors_list[:10]))\n",
    "print(\"The total number of authors is {}\".format(len(authors_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 385 authors in the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets.\n",
    "\n",
    "In this section, we will create the train/test split of our data for training our model. We use the concatenated values for visitor id and content id to create a farm fingerprint, taking approximately 90% of the data for the training set and 10% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>months_since_epoch</th>\n",
       "      <th>next_content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054303894414213464</td>\n",
       "      <td>299804373</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Bloggerin wegen Anstiftung zur Magersucht ange...</td>\n",
       "      <td>Elisabeth Mittendorfer</td>\n",
       "      <td>574</td>\n",
       "      <td>299937546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1054303894414213464</td>\n",
       "      <td>299437612</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Wenn Omi wieder nach der Liebe sucht</td>\n",
       "      <td>Yvonne Widler</td>\n",
       "      <td>574</td>\n",
       "      <td>299437612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1087837873805535641</td>\n",
       "      <td>299982579</td>\n",
       "      <td>News</td>\n",
       "      <td>VIDEO: Basejumper springen von Berg in Flugzeug</td>\n",
       "      <td>Mathias Kainz</td>\n",
       "      <td>574</td>\n",
       "      <td>187077794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1089650513224730843</td>\n",
       "      <td>299781837</td>\n",
       "      <td>News</td>\n",
       "      <td>Mordalarm in Wien: 31 Jahre alte Frau erstochen</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299825001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1089650513224730843</td>\n",
       "      <td>299825001</td>\n",
       "      <td>News</td>\n",
       "      <td>Auslieferung: Mutmaßlicher Sechsfach-Mörder ha...</td>\n",
       "      <td>Michaela Reibenwein</td>\n",
       "      <td>574</td>\n",
       "      <td>299836800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            visitor_id content_id   category  \\\n",
       "0  1054303894414213464  299804373  Lifestyle   \n",
       "1  1054303894414213464  299437612  Lifestyle   \n",
       "2  1087837873805535641  299982579       News   \n",
       "3  1089650513224730843  299781837       News   \n",
       "4  1089650513224730843  299825001       News   \n",
       "\n",
       "                                               title                  author  \\\n",
       "0  Bloggerin wegen Anstiftung zur Magersucht ange...  Elisabeth Mittendorfer   \n",
       "1               Wenn Omi wieder nach der Liebe sucht           Yvonne Widler   \n",
       "2    VIDEO: Basejumper springen von Berg in Flugzeug           Mathias Kainz   \n",
       "3    Mordalarm in Wien: 31 Jahre alte Frau erstochen                    None   \n",
       "4  Auslieferung: Mutmaßlicher Sechsfach-Mörder ha...     Michaela Reibenwein   \n",
       "\n",
       "   months_since_epoch next_content_id  \n",
       "0                 574       299937546  \n",
       "1                 574       299437612  \n",
       "2                 574       187077794  \n",
       "3                 574       299825001  \n",
       "4                 574       299836800  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "WITH site_history as (\n",
    "  SELECT\n",
    "      fullVisitorId as visitor_id,\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id,\n",
    "      (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category, \n",
    "      (SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title,\n",
    "      (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) AS author_list,\n",
    "      SPLIT(RPAD((SELECT MAX(IF(index=4, value, NULL)) FROM UNNEST(hits.customDimensions)), 7), '.') as year_month_array,\n",
    "      LEAD(hits.customDimensions, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) as nextCustomDimensions\n",
    "  FROM \n",
    "    `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "     UNNEST(hits) AS hits\n",
    "   WHERE \n",
    "     # only include hits on pages\n",
    "      hits.type = \"PAGE\"\n",
    "      AND\n",
    "      fullVisitorId IS NOT NULL\n",
    "      AND\n",
    "      hits.time != 0\n",
    "      AND\n",
    "      hits.time IS NOT NULL\n",
    "      AND\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  visitor_id,\n",
    "  content_id,\n",
    "  category,\n",
    "  REGEXP_REPLACE(title, r\",\", \"\") as title,\n",
    "  REGEXP_EXTRACT(author_list, r\"^[^,]+\") as author,\n",
    "  DATE_DIFF(DATE(CAST(year_month_array[OFFSET(0)] AS INT64), CAST(year_month_array[OFFSET(1)] AS INT64), 1), DATE(1970,1,1), MONTH) as months_since_epoch,\n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) as next_content_id\n",
    "FROM\n",
    "  site_history\n",
    "WHERE (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) IS NOT NULL\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(CONCAT(visitor_id, content_id)), 10)) < 9\n",
    "\"\"\"\n",
    "training_set_df = bigquery.Client().query(sql).to_dataframe()\n",
    "training_set_df.to_csv('training_set.csv', header=False, index=False, encoding='utf-8')\n",
    "training_set_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>months_since_epoch</th>\n",
       "      <th>next_content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1112146297759656551</td>\n",
       "      <td>299915364</td>\n",
       "      <td>News</td>\n",
       "      <td>Glyphosat-Verlängerung: SPD wirft CDU Vertraue...</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299836255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1134243174384296784</td>\n",
       "      <td>299964154</td>\n",
       "      <td>News</td>\n",
       "      <td>Neue Seidenstraße: Ein chinesischer Keil in Eu...</td>\n",
       "      <td>Hermann Sileitsch-Parzer</td>\n",
       "      <td>574</td>\n",
       "      <td>299933565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1153984497631281150</td>\n",
       "      <td>299800661</td>\n",
       "      <td>Stars &amp; Kultur</td>\n",
       "      <td>Meghan Markle im Porträt - Vom TV-Sternchen zu...</td>\n",
       "      <td>Christina Michlits</td>\n",
       "      <td>574</td>\n",
       "      <td>299906166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13826028694672839081</td>\n",
       "      <td>299836800</td>\n",
       "      <td>News</td>\n",
       "      <td>Protest: Gesichtsscanner in Apotheke  abgedreht</td>\n",
       "      <td>Wolfgang Atzenhofer</td>\n",
       "      <td>574</td>\n",
       "      <td>299866366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1444851807585783223</td>\n",
       "      <td>299934703</td>\n",
       "      <td>News</td>\n",
       "      <td>Verkehrsunfall im Mühlviertel ließ Autoschiebe...</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>299930679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             visitor_id content_id        category  \\\n",
       "0   1112146297759656551  299915364            News   \n",
       "1   1134243174384296784  299964154            News   \n",
       "2   1153984497631281150  299800661  Stars & Kultur   \n",
       "3  13826028694672839081  299836800            News   \n",
       "4   1444851807585783223  299934703            News   \n",
       "\n",
       "                                               title  \\\n",
       "0  Glyphosat-Verlängerung: SPD wirft CDU Vertraue...   \n",
       "1  Neue Seidenstraße: Ein chinesischer Keil in Eu...   \n",
       "2  Meghan Markle im Porträt - Vom TV-Sternchen zu...   \n",
       "3    Protest: Gesichtsscanner in Apotheke  abgedreht   \n",
       "4  Verkehrsunfall im Mühlviertel ließ Autoschiebe...   \n",
       "\n",
       "                     author  months_since_epoch next_content_id  \n",
       "0                      None                 574       299836255  \n",
       "1  Hermann Sileitsch-Parzer                 574       299933565  \n",
       "2        Christina Michlits                 574       299906166  \n",
       "3       Wolfgang Atzenhofer                 574       299866366  \n",
       "4                      None                 574       299930679  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql=\"\"\"\n",
    "WITH site_history as (\n",
    "  SELECT\n",
    "      fullVisitorId as visitor_id,\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id,\n",
    "      (SELECT MAX(IF(index=7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category, \n",
    "      (SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title,\n",
    "      (SELECT MAX(IF(index=2, value, NULL)) FROM UNNEST(hits.customDimensions)) AS author_list,\n",
    "      SPLIT(RPAD((SELECT MAX(IF(index=4, value, NULL)) FROM UNNEST(hits.customDimensions)), 7), '.') as year_month_array,\n",
    "      LEAD(hits.customDimensions, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) as nextCustomDimensions\n",
    "  FROM \n",
    "    `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "     UNNEST(hits) AS hits\n",
    "   WHERE \n",
    "     # only include hits on pages\n",
    "      hits.type = \"PAGE\"\n",
    "      AND\n",
    "      fullVisitorId IS NOT NULL\n",
    "      AND\n",
    "      hits.time != 0\n",
    "      AND\n",
    "      hits.time IS NOT NULL\n",
    "      AND\n",
    "      (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  visitor_id,\n",
    "  content_id,\n",
    "  category,\n",
    "  REGEXP_REPLACE(title, r\",\", \"\") as title,\n",
    "  REGEXP_EXTRACT(author_list, r\"^[^,]+\") as author,\n",
    "  DATE_DIFF(DATE(CAST(year_month_array[OFFSET(0)] AS INT64), CAST(year_month_array[OFFSET(1)] AS INT64), 1), DATE(1970,1,1), MONTH) as months_since_epoch,\n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) as next_content_id\n",
    "FROM\n",
    "  site_history\n",
    "WHERE (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) IS NOT NULL\n",
    "      AND ABS(MOD(FARM_FINGERPRINT(CONCAT(visitor_id, content_id)), 10)) >= 9\n",
    "\"\"\"\n",
    "test_set_df = bigquery.Client().query(sql).to_dataframe()\n",
    "test_set_df.to_csv('test_set.csv', header=False, index=False, encoding='utf-8')\n",
    "test_set_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the two csv files we just created containing the training and test set. We'll also do a line count of both files to confirm that we have achieved an approximate 90/10 train/test split.  \n",
    "In the next notebook, **Content Based Filtering** we will build a model to recommend an article given information about the current article being read, such as the category, title, author, and publish date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25599 test_set.csv\n",
      "  232308 training_set.csv\n",
      "  257907 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l *_set.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> test_set.csv <==\n",
      "1112146297759656551,299915364,News,Glyphosat-Verlängerung: SPD wirft CDU Vertrauensbruch vor,,574,299836255\n",
      "1134243174384296784,299964154,News,Neue Seidenstraße: Ein chinesischer Keil in Europa,Hermann Sileitsch-Parzer,574,299933565\n",
      "1153984497631281150,299800661,Stars & Kultur,Meghan Markle im Porträt - Vom TV-Sternchen zur Prinzessin,Christina Michlits,574,299906166\n",
      "13826028694672839081,299836800,News,Protest: Gesichtsscanner in Apotheke  abgedreht,Wolfgang Atzenhofer,574,299866366\n",
      "1444851807585783223,299934703,News,Verkehrsunfall im Mühlviertel ließ Autoschieber-Bande auffliegen,,574,299930679\n",
      "1444851807585783223,299934703,News,Verkehrsunfall im Mühlviertel ließ Autoschieber-Bande auffliegen,,574,299181999\n",
      "1563082078176046230,299772450,Stars & Kultur,\"Kritik an Prinz Harry: \"\"Ein verzogener Rotzlöffel\"\"\",Elisabeth Spitzer,574,299800661\n",
      "1729486252465286166,175262203,Lifestyle,Tansania: Die Hilfsprojekte von Christine Wallner,,552,175262218\n",
      "1859931483041799173,299986548,News,Nachrichtenagentur: Nordkorea feuerte erneut Rakete ab,Stefan Berndl,574,299957318\n",
      "1872470734565833329,299861625,News,So gefährlich können Social Media sein,Helmut Brandstätter,574,299830996\n",
      "\n",
      "==> training_set.csv <==\n",
      "1054303894414213464,299804373,Lifestyle,Bloggerin wegen Anstiftung zur Magersucht angezeigt,Elisabeth Mittendorfer,574,299937546\n",
      "1054303894414213464,299437612,Lifestyle,Wenn Omi wieder nach der Liebe sucht,Yvonne Widler,574,299437612\n",
      "1087837873805535641,299982579,News,VIDEO: Basejumper springen von Berg in Flugzeug,Mathias Kainz,574,187077794\n",
      "1089650513224730843,299781837,News,Mordalarm in Wien: 31 Jahre alte Frau erstochen,,574,299825001\n",
      "1089650513224730843,299825001,News,Auslieferung: Mutmaßlicher Sechsfach-Mörder hat Flugangst,Michaela Reibenwein,574,299836800\n",
      "1091557392697552592,299692362,Stars & Kultur,\"\"\"Unsere Zivilisation zerbricht\"\"\",Peter Jarolin,574,299116765\n",
      "1091557392697552592,299116765,Stars & Kultur,Übergriffsvorwürfe gegen Pixar-Animationsguru Lasseter,Georg Leyrer,574,299949793\n",
      "1094175364281853481,299818044,News,Lehrer am Gymnasium Schwechat suspendiert,,574,299852437\n",
      "1094175364281853481,299818044,News,Lehrer am Gymnasium Schwechat suspendiert,,574,299824001\n",
      "1094175364281853481,299824001,News,Streit um Sieg bei Präsidentenwahl in Honduras,Peter Temel,574,299866366\n"
     ]
    }
   ],
   "source": [
    "!head *_set.csv"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf-gpu.1-15.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
