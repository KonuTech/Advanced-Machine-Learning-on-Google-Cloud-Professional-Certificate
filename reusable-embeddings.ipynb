{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained embedding with Tensorflow Hub\n",
    "\n",
    "**Learning Objectives**\n",
    "1. How to instantiate a Tensorflow Hub module\n",
    "1. How to find pretrained Tensorflow Hub module for variety of purposes\n",
    "1. How to use a pre-trained TF Hub text modules to generate sentence vectors\n",
    "1. How to incorporate a pre-trained TF-Hub module into a Keras model\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "In this notebook, we will implement text models to recognize the probable source (Github, Tech-Crunch, or The New-York Times) of the titles we have in the title dataset.\n",
    "\n",
    "First, we will load and pre-process the texts and labels so that they are suitable to be fed to sequential Keras models with first layer being TF-hub pre-trained modules. Thanks to this first layer, we won't need to tokenize and integerize the text before passing it to our models. The pre-trained layer will take care of that for us, and consume directly raw text. However, we will still have to one-hot-encode each of the 3 classes into a 3 dimensional basis vector.\n",
    "\n",
    "Then we will build, train and compare simple models starting with different pre-trained TF-Hub layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nny3m465gKkY"
   },
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nny3m465gKkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery==1.25.0 in /home/jupyter/.local/lib/python3.7/site-packages (1.25.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (3.17.3)\n",
      "Requirement already satisfied: google-api-core<2.0dev,>=1.15.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.31.3)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.1.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.7.2)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.9.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.35.0)\n",
      "Requirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.16.0)\n",
      "Requirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (0.5.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (58.2.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.53.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.2.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user google-cloud-bigquery==1.25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Restart your kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kindly ignore the deprecation warnings and incompatibility errors related to google-cloud-storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The google.cloud.bigquery extension is already loaded. To reload it, use:\n",
      "  %reload_ext google.cloud.bigquery\n"
     ]
    }
   ],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the variable values in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"qwiklabs-gcp-01-2c110aedb9fe\"  # Replace with your PROJECT\n",
    "BUCKET = PROJECT  # defaults to PROJECT\n",
    "REGION = \"us-east1\"  # Replace with your REGION\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset from BigQuery \n",
    "\n",
    "Hacker news headlines are available as a BigQuery public dataset. The [dataset](https://bigquery.cloud.google.com/table/bigquery-public-data:hacker_news.stories?tab=details) contains all headlines from the sites inception in October 2006 until October 2015. \n",
    "\n",
    "Here is a sample of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.dumpert.nl/mediabase/6560049/3eb18e...</td>\n",
       "      <td>Calling the NSA: \"I accidentally deleted an e-...</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://blog.liip.ch/archive/2013/10/28/hhvm-an...</td>\n",
       "      <td>Amazing performance with HHVM and PHP with a S...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.gamedev.net/page/resources/_/techni...</td>\n",
       "      <td>A Journey Through the CPU Pipeline</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://jfarcand.wordpress.com/2011/02/25/atmos...</td>\n",
       "      <td>Atmosphere Framework 0.7 released: GWT, Wicket...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://tech.gilt.com/post/90578399884/immutabl...</td>\n",
       "      <td>Immutable Infrastructure with Docker and EC2 [...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://thechangelog.com/post/501053444/episode...</td>\n",
       "      <td>Changelog 0.2.0 - node.js w/Felix Geisendorfer</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://openangelforum.com/2010/09/09/second-bo...</td>\n",
       "      <td>Second Open Angel Forum in Boston Oct 13th--fr...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://bredele.github.io/async</td>\n",
       "      <td>A collection of JavaScript asynchronous patterns</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://www.smashingmagazine.com/2007/08/25/20-...</td>\n",
       "      <td>20 Free and Fresh Icon Sets</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://www.cio.com/article/147801/Study_Finds_...</td>\n",
       "      <td>Study: Only 1 in 5 Workers is \"Engaged\" in The...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.dumpert.nl/mediabase/6560049/3eb18e...   \n",
       "1  http://blog.liip.ch/archive/2013/10/28/hhvm-an...   \n",
       "2  http://www.gamedev.net/page/resources/_/techni...   \n",
       "3  http://jfarcand.wordpress.com/2011/02/25/atmos...   \n",
       "4  http://tech.gilt.com/post/90578399884/immutabl...   \n",
       "5  http://thechangelog.com/post/501053444/episode...   \n",
       "6  http://openangelforum.com/2010/09/09/second-bo...   \n",
       "7                     http://bredele.github.io/async   \n",
       "8  http://www.smashingmagazine.com/2007/08/25/20-...   \n",
       "9  http://www.cio.com/article/147801/Study_Finds_...   \n",
       "\n",
       "                                               title  score  \n",
       "0  Calling the NSA: \"I accidentally deleted an e-...    258  \n",
       "1  Amazing performance with HHVM and PHP with a S...     11  \n",
       "2                 A Journey Through the CPU Pipeline     11  \n",
       "3  Atmosphere Framework 0.7 released: GWT, Wicket...     11  \n",
       "4  Immutable Infrastructure with Docker and EC2 [...     11  \n",
       "5     Changelog 0.2.0 - node.js w/Felix Geisendorfer     11  \n",
       "6  Second Open Angel Forum in Boston Oct 13th--fr...     11  \n",
       "7   A collection of JavaScript asynchronous patterns     11  \n",
       "8                        20 Free and Fresh Icon Sets     11  \n",
       "9  Study: Only 1 in 5 Workers is \"Engaged\" in The...     11  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "\n",
    "SELECT\n",
    "    url, title, score\n",
    "FROM\n",
    "    `bigquery-public-data.hacker_news.stories`\n",
    "WHERE\n",
    "    LENGTH(title) > 10\n",
    "    AND score > 10\n",
    "    AND LENGTH(url) > 0\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some regular expression parsing in BigQuery to get the source of the newspaper article from the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>num_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogspot</td>\n",
       "      <td>41386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>github</td>\n",
       "      <td>36525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>techcrunch</td>\n",
       "      <td>30891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youtube</td>\n",
       "      <td>30848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>28787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>f5</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>gamasutra</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>cnbc</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>indiatimes</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>computerworlduk</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source  num_articles\n",
       "0          blogspot         41386\n",
       "1            github         36525\n",
       "2        techcrunch         30891\n",
       "3           youtube         30848\n",
       "4           nytimes         28787\n",
       "..              ...           ...\n",
       "95               f5          1254\n",
       "96        gamasutra          1249\n",
       "97             cnbc          1229\n",
       "98       indiatimes          1223\n",
       "99  computerworlduk          1166\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery --project $PROJECT\n",
    "\n",
    "SELECT\n",
    "    ARRAY_REVERSE(SPLIT(REGEXP_EXTRACT(url, '.*://(.[^/]+)/'), '.'))[OFFSET(1)] AS source,\n",
    "    COUNT(title) AS num_articles\n",
    "FROM\n",
    "    `bigquery-public-data.hacker_news.stories`\n",
    "WHERE\n",
    "    REGEXP_CONTAINS(REGEXP_EXTRACT(url, '.*://(.[^/]+)/'), '.com$')\n",
    "    AND LENGTH(title) > 10\n",
    "GROUP BY\n",
    "    source\n",
    "ORDER BY num_articles DESC\n",
    "  LIMIT 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have good parsing of the URL to get the source, let's put together a dataset of source and titles. This will be our labeled dataset for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT \n",
      "    LOWER(REGEXP_REPLACE(title, '[^a-zA-Z0-9 $.-]', ' ')) AS title,\n",
      "    source\n",
      "FROM\n",
      "  (\n",
      "SELECT\n",
      "    title,\n",
      "    ARRAY_REVERSE(SPLIT(REGEXP_EXTRACT(url, '.*://(.[^/]+)/'), '.'))[OFFSET(1)] AS source\n",
      "    \n",
      "FROM\n",
      "    `bigquery-public-data.hacker_news.stories`\n",
      "WHERE\n",
      "    REGEXP_CONTAINS(REGEXP_EXTRACT(url, '.*://(.[^/]+)/'), '.com$')\n",
      "    AND LENGTH(title) > 10\n",
      ")\n",
      "WHERE (source = 'github' OR source = 'nytimes' OR source = 'techcrunch')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex = '.*://(.[^/]+)/'\n",
    "\n",
    "\n",
    "sub_query = \"\"\"\n",
    "SELECT\n",
    "    title,\n",
    "    ARRAY_REVERSE(SPLIT(REGEXP_EXTRACT(url, '{0}'), '.'))[OFFSET(1)] AS source\n",
    "    \n",
    "FROM\n",
    "    `bigquery-public-data.hacker_news.stories`\n",
    "WHERE\n",
    "    REGEXP_CONTAINS(REGEXP_EXTRACT(url, '{0}'), '.com$')\n",
    "    AND LENGTH(title) > 10\n",
    "\"\"\".format(regex)\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    LOWER(REGEXP_REPLACE(title, '[^a-zA-Z0-9 $.-]', ' ')) AS title,\n",
    "    source\n",
    "FROM\n",
    "  ({sub_query})\n",
    "WHERE (source = 'github' OR source = 'nytimes' OR source = 'techcrunch')\n",
    "\"\"\".format(sub_query=sub_query)\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ML training, we usually need to split our dataset into training and evaluation datasets (and perhaps an independent test dataset if we are going to do model or feature selection based on the evaluation dataset). AutoML however figures out on its own how to create these splits, so we won't need to do that here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this guy just found out how to bypass adblocker</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show hn  dodo   command line task management f...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>without coding test  test automation for javas...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clojure s first code commit  authored 8 years ...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hikaricp a solid high-performance jdbc connect...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  source\n",
       "0    this guy just found out how to bypass adblocker  github\n",
       "1  show hn  dodo   command line task management f...  github\n",
       "2  without coding test  test automation for javas...  github\n",
       "3  clojure s first code commit  authored 8 years ...  github\n",
       "4  hikaricp a solid high-performance jdbc connect...  github"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq = bigquery.Client(project=PROJECT)\n",
    "title_dataset = bq.query(query).to_dataframe()\n",
    "title_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96203 entries, 0 to 96202\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   96203 non-null  object\n",
      " 1   source  96203 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "title_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoML for text classification requires that\n",
    "* the dataset be in csv form with \n",
    "* the first column being the texts to classify or a GCS path to the text \n",
    "* the last column to be the text labels\n",
    "\n",
    "The dataset we pulled from BiqQuery satisfies these requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full dataset contains 96203 titles\n"
     ]
    }
   ],
   "source": [
    "print(\"The full dataset contains {n} titles\".format(n=len(title_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we have roughly the same number of labels for each of our three labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github        36525\n",
       "techcrunch    30891\n",
       "nytimes       28787\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_dataset.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will save our data, which is currently in-memory, to disk.\n",
    "\n",
    "We will create a csv file containing the full dataset and another containing only 1000 articles for development.\n",
    "\n",
    "**Note:** It may take a long time to train AutoML on the full dataset, so we recommend to use the sample dataset for the purpose of learning the tool. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = './data/'\n",
    "\n",
    "if not os.path.exists(DATADIR):\n",
    "    os.makedirs(DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DATASET_NAME = 'titles_full.csv'\n",
    "FULL_DATASET_PATH = os.path.join(DATADIR, FULL_DATASET_NAME)\n",
    "\n",
    "# Let's shuffle the data before writing it to disk.\n",
    "title_dataset = title_dataset.sample(n=len(title_dataset))\n",
    "\n",
    "title_dataset.to_csv(\n",
    "    FULL_DATASET_PATH, header=False, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's sample 1000 articles from the full dataset and make sure we have enough examples for each label in our sample dataset (see [here](https://cloud.google.com/natural-language/automl/docs/beginners-guide) for further details on how to prepare data for AutoML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github        370\n",
       "techcrunch    323\n",
       "nytimes       307\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_title_dataset = title_dataset.sample(n=1000)\n",
    "sample_title_dataset.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the sample datatset to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DATASET_NAME = 'titles_sample.csv'\n",
    "SAMPLE_DATASET_PATH = os.path.join(DATADIR, SAMPLE_DATASET_NAME)\n",
    "\n",
    "sample_title_dataset.to_csv(\n",
    "    SAMPLE_DATASET_PATH, header=False, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40709</th>\n",
       "      <td>intelligence startup goes behind enemy lines t...</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80045</th>\n",
       "      <td>the madness stops here - don t pay a vc any fees</td>\n",
       "      <td>techcrunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44374</th>\n",
       "      <td>shifting careers - making artistic careers luc...</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25664</th>\n",
       "      <td>a virtual dom and diffing algorithm</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95175</th>\n",
       "      <td>one month  yc s13  raises $770k to teach all o...</td>\n",
       "      <td>techcrunch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      source\n",
       "40709  intelligence startup goes behind enemy lines t...     nytimes\n",
       "80045   the madness stops here - don t pay a vc any fees  techcrunch\n",
       "44374  shifting careers - making artistic careers luc...     nytimes\n",
       "25664                a virtual dom and diffing algorithm      github\n",
       "95175  one month  yc s13  raises $770k to teach all o...  techcrunch"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_title_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow_hub import KerasLayer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by specifying where the information about the trained models will be saved as well as where our dataset is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./text_models\"\n",
    "DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous labs, our dataset consists of titles of articles along with the label indicating from which source these articles have been taken from (GitHub, Tech-Crunch, or the New-York Times):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles_full.csv  titles_sample.csv\n"
     ]
    }
   ],
   "source": [
    "ls ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bup   git based file backup system</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gamesalad raises $6.1 million for iphone and i...</td>\n",
       "      <td>techcrunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>show hn  using paperclip to build a simple ima...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wonga  how the net should kill the finance ind...</td>\n",
       "      <td>techcrunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how to beat high airfares</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      source\n",
       "0                 bup   git based file backup system      github\n",
       "1  gamesalad raises $6.1 million for iphone and i...  techcrunch\n",
       "2  show hn  using paperclip to build a simple ima...      github\n",
       "3  wonga  how the net should kill the finance ind...  techcrunch\n",
       "4                          how to beat high airfares     nytimes"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_NAME = \"titles_full.csv\"\n",
    "TITLE_SAMPLE_PATH = os.path.join(DATA_DIR, DATASET_NAME)\n",
    "COLUMNS = ['title', 'source']\n",
    "\n",
    "titles_df = pd.read_csv(TITLE_SAMPLE_PATH, header=None, names=COLUMNS)\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at the number of examples per label to make sure we have a well-balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github        36525\n",
       "techcrunch    30891\n",
       "nytimes       28787\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will use pre-trained [TF-Hub embeddings modules for english](https://tfhub.dev/s?q=tf2%20embeddings%20text%20english) for the first layer of our models. One immediate\n",
    "advantage of doing so is that the TF-Hub embedding module will take care for us of processing the raw text. \n",
    "This also means that our model will be able to consume text directly instead of sequences of integers representing the words.\n",
    "\n",
    "However, as before, we still need to preprocess the labels into one-hot-encoded vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    'github': 0,\n",
    "    'nytimes': 1,\n",
    "    'techcrunch': 2\n",
    "}\n",
    "N_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(sources):\n",
    "    classes = [CLASSES[source] for source in sources]\n",
    "    one_hots = to_categorical(classes, num_classes=N_CLASSES)\n",
    "    return one_hots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_labels(titles_df.source[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our data into train and test splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = int(len(titles_df) * 0.95)\n",
    "\n",
    "titles_train, sources_train = (\n",
    "    titles_df.title[:N_TRAIN], titles_df.source[:N_TRAIN])\n",
    "\n",
    "titles_valid, sources_valid = (\n",
    "    titles_df.title[N_TRAIN:], titles_df.source[N_TRAIN:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be on the safe side, we verify that the train and test splits\n",
    "have roughly the same number of examples per class.\n",
    "\n",
    "Since it is the case, accuracy will be a good metric to use to measure\n",
    "the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github        34666\n",
       "techcrunch    29346\n",
       "nytimes       27380\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github        1859\n",
       "techcrunch    1545\n",
       "nytimes       1407\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_valid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the features and labels we will feed our models with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = titles_train.values, encode_labels(sources_train)\n",
    "X_valid, Y_valid = titles_valid.values, encode_labels(sources_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bup   git based file backup system',\n",
       "       'gamesalad raises $6.1 million for iphone and ipad game creation tool',\n",
       "       'show hn  using paperclip to build a simple image upload service'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try a word embedding pre-trained using a [Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). TF-Hub has a 50-dimensional one called \n",
    "[nnlm-en-dim50-with-normalization](https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1), which also\n",
    "normalizes the vectors produced. \n",
    "\n",
    "Once loaded from its url, the TF-hub module can be used as a normal Keras layer in a sequential or functional model. Since we have enough data to fine-tune the parameters of the pre-trained embedding itself, we will set `trainable=True` in the `KerasLayer` that loads the pre-trained embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 11:00:10.094150: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-01 11:00:10.159300: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "NNLM = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "\n",
    "nnlm_module = KerasLayer(\n",
    "    NNLM, output_shape=[50], input_shape=[], dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this TF-Hub embedding produces a single 50-dimensional vector when passed a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
       "array([[ 0.19331802,  0.05893906,  0.15330684,  0.2505918 ,  0.19369544,\n",
       "         0.03578748,  0.07387847, -0.10962156, -0.11377034,  0.07172022,\n",
       "         0.12458669, -0.02289705, -0.18177685, -0.07084437, -0.00225849,\n",
       "        -0.36875236,  0.05772953, -0.14222091,  0.08765972, -0.14068899,\n",
       "        -0.07005888, -0.20634466,  0.07220475,  0.04258814,  0.0955702 ,\n",
       "         0.19424029, -0.42492998, -0.00706906, -0.02095   , -0.05055764,\n",
       "        -0.18988201, -0.02841404,  0.13222624, -0.01459922, -0.31255388,\n",
       "        -0.09577855,  0.05469003, -0.13858607,  0.01141668, -0.12352604,\n",
       "        -0.07250367, -0.11605677, -0.06976165,  0.14313601, -0.15183711,\n",
       "        -0.06836402,  0.03054246, -0.13259597, -0.14599673,  0.05094011]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnlm_module(tf.constant([\"The dog is happy to see people in the street.\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function that \n",
    "\n",
    "* takes as input an instance of a `KerasLayer` (i.e. the `nnlm_module` we constructed above) as well as the name of the model (say `nnlm`)\n",
    "* returns a compiled Keras sequential model starting with this pre-trained TF-hub layer, adding one or more dense relu layers to it, and ending with a softmax layer giving the probability of each of the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hub_module, name):\n",
    "    model = Sequential([\n",
    "        hub_module, # TODO \n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(N_CLASSES, activation='softmax')\n",
    "    ], name=name)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also wrap the training code into a `train_and_evaluate` function that \n",
    "* takes as input the training and validation data, as well as the compiled model itself, and the `batch_size`\n",
    "* trains the compiled model for 100 epochs at most, and does early-stopping when the validation loss is no longer decreasing\n",
    "* returns an `history` object, which will help us to plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_data, val_data, model, batch_size=5000):\n",
    "    X_train, Y_train = train_data\n",
    "\n",
    "    tf.random.set_seed(33)\n",
    "\n",
    "    model_dir = os.path.join(MODEL_DIR, model.name)\n",
    "    if tf.io.gfile.exists(model_dir):\n",
    "        tf.io.gfile.rmtree(model_dir)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        epochs=100,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=val_data,\n",
    "        callbacks=[EarlyStopping(), TensorBoard(model_dir)],\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NNLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (X_train, Y_train)\n",
    "val_data = (X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 11:00:11.242005: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-01 11:00:11.242051: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-01 11:00:11.242211: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/19 [>.............................] - ETA: 17s - loss: 1.1018 - accuracy: 0.3506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 11:00:12.338070: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-01 11:00:12.338118: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/19 [==>...........................] - ETA: 6s - loss: 1.1005 - accuracy: 0.3556 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-01 11:00:12.721417: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-01 11:00:12.723512: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-01 11:00:12.725597: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12\n",
      "\n",
      "2021-11-01 11:00:12.726910: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12/tensorflow-2-6-20211101-110114.trace.json.gz\n",
      "2021-11-01 11:00:12.732276: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12\n",
      "\n",
      "2021-11-01 11:00:12.733319: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12/tensorflow-2-6-20211101-110114.memory_profile.json.gz\n",
      "2021-11-01 11:00:12.733746: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12\n",
      "Dumped tool data for xplane.pb to ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12/tensorflow-2-6-20211101-110114.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12/tensorflow-2-6-20211101-110114.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12/tensorflow-2-6-20211101-110114.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12/tensorflow-2-6-20211101-110114.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./text_models/nnlm/train/plugins/profile/2021_11_01_11_00_12/tensorflow-2-6-20211101-110114.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 8s 385ms/step - loss: 1.0625 - accuracy: 0.4786 - val_loss: 1.0107 - val_accuracy: 0.5963\n"
     ]
    }
   ],
   "source": [
    "nnlm_model = build_model(nnlm_module, 'nnlm')\n",
    "nnlm_history = train_and_evaluate(data, val_data, nnlm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = nnlm_history\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to beat the best model by modifying the model architecture, changing the TF-Hub embedding, and tweaking the training parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
